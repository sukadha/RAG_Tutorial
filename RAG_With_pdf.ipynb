{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02362b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156c3bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.environ['OPENAI_API_KEY']:\n",
    "    print(\"API Key is set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77ced0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7159f4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-5-nano\",temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfb2fe0",
   "metadata": {},
   "source": [
    "### RAG Implementation with PDFs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727b6a0e",
   "metadata": {},
   "source": [
    "### Step 1: Extracting Text from PDFs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a87f8d6",
   "metadata": {},
   "source": [
    "### in terminal add this line\n",
    "\n",
    "-> uv add pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c691c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "pdf_path = r\"C:/Users/koppa/Downloads/RAG_Tutorial/FAANGPath_Simple_Template__1___Copy_ (2).pdf\"\n",
    "\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b083d8",
   "metadata": {},
   "source": [
    "# or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ea52ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"C:/Users/koppa/Downloads/RAG_Tutorial/FAANGPath_Simple_Template__1___Copy_ (2).pdf\")\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "docs  # docs.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e68e25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[0].metadata # content and metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2689098c",
   "metadata": {},
   "source": [
    "### *Creating Own Metadata for PDF Chunks*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ba73f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in docs:\n",
    "    i.metadata = {\"source\": \"FAANGPath_Simple_Template__1___Copy_ (2).pdf\",\n",
    "    \"author\": \"sukadha\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e41e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[0].metadata # content and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff3dc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b28ba7",
   "metadata": {},
   "source": [
    "### Step 2 : Splitting the Document into CHUNKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d0d6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "## It divides the document into multiple chunks and adds metadata to each chunk\n",
    "\n",
    "from langchain_core.text_splitter import RecursiveCharacterTextSplitter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e53b4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "chunks = splitter.split_documents(docs)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9470ab65",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks[0].metadata # content and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169ad99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(chunks) #652 means -> vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca18eb85",
   "metadata": {},
   "source": [
    "### Step 3 : Creating Embeddings for the chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c6b964",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0c2932",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43522630",
   "metadata": {},
   "source": [
    "### Step 4 : Create and store embeddings in vector store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b72b742",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e66b3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(documents=chunks,embedding=embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5e1176",
   "metadata": {},
   "source": [
    "### Step 5 : Semantic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d48bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore.similarity_search(\"What is the Summary? Tell me in one Line\", k =3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c1aa3a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce15f8a3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de29fcf3",
   "metadata": {},
   "source": [
    "### Reset the kernel and start running from this code after doing the top codes in run using with Vector folder we no need to run every time of the top above code just below of the codes you run its enough"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7581bdc",
   "metadata": {},
   "source": [
    "### Step 3 : Creating Embeddings for the chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5df749a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a02a9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244d0ea1",
   "metadata": {},
   "source": [
    "### Step 4.1 : Create and Store Embedding in Local vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d90477",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=docs,\n",
    "                                    embedding=embedding_model,  \n",
    "                                    persist_directory=\"./Vector\")  # i created a new folder name is Vector to store the vector database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6e609c",
   "metadata": {},
   "source": [
    "### Re-Use the Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8a4733",
   "metadata": {},
   "outputs": [],
   "source": [
    "vecotrstore_persist = Chroma(\n",
    "                             persist_directory=\"./Vector\", \n",
    "                             embedding_function=embedding_model\n",
    "                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6439384",
   "metadata": {},
   "source": [
    "### Step 5 : Semantic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e185fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore_persist.similarity_search(\"What is the Summary? Tell me in one Line\", k =3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
